{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env: AppCurateGEO \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def process_gse(gse_id, super_series=None):                                       \n",
    "    # If SuperSeries is not set, use the current GSE\n",
    "    if not super_series:\n",
    "        super_series = gse_id\n",
    "\n",
    "    url = f\"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={gse_id}\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    desired_fields = [\n",
    "        \"Title\",\n",
    "        \"Summary\",\n",
    "        \"Overall design\",\n",
    "        \"Contact name\",\n",
    "        \"E-mail(s)\",\n",
    "        \"Phone\",\n",
    "        \"Organization name\",\n",
    "        \"Department\",\n",
    "        \"Lab\",\n",
    "        \"City\",\n",
    "        \"State/province\",\n",
    "        \"Country\",\n",
    "    ]\n",
    "\n",
    "    data = {}\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) == 2:\n",
    "            label = cols[0].get_text(strip=True)\n",
    "            value = cols[1].get_text(strip=True)\n",
    "            if label in desired_fields:\n",
    "                data[label] = value\n",
    "\n",
    "    # Get platforms & samples from SOFT\n",
    "    soft_url = f\"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={gse_id}&format=soft\"\n",
    "    soft_response = requests.get(soft_url)\n",
    "    soft_text = soft_response.text\n",
    "\n",
    "    platforms = set(re.findall(r\"(GPL\\d+)\", soft_text))\n",
    "    platforms_str = \", \".join(sorted(platforms))\n",
    "    samples = set(re.findall(r\"(GSM\\d+)\", soft_text))\n",
    "    num_samples = len(samples)\n",
    "\n",
    "    data[\"Platforms\"] = platforms_str\n",
    "    data[\"Samples\"] = num_samples\n",
    "    data[\"Series\"] = gse_id\n",
    "    data[\"SuperSeries\"] = super_series\n",
    "\n",
    "    supp_data = []\n",
    "\n",
    "    # -------------------------\n",
    "    # Case 1: Selenium \"(custom)\" scraping if link exists\n",
    "    # -------------------------\n",
    "    if soup.find(\"a\", string=\"(custom)\"):\n",
    "        driver = webdriver.Chrome()\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            wait = WebDriverWait(driver, 10)\n",
    "\n",
    "            custom_link = wait.until(\n",
    "                EC.element_to_be_clickable((By.LINK_TEXT, \"(custom)\"))\n",
    "            )\n",
    "            custom_link.click()\n",
    "\n",
    "            # Wait until file table loads\n",
    "            wait.until(EC.presence_of_all_elements_located(\n",
    "                (By.XPATH, \"//table//tr[td/input[@type='checkbox']]\")\n",
    "            ))\n",
    "\n",
    "            # Rows with checkboxes\n",
    "            rows = driver.find_elements(By.XPATH, \"//table//tr[td/input[@type='checkbox']]\")\n",
    "\n",
    "            for row in rows:\n",
    "                cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "                if len(cells) >= 2:\n",
    "                    file_name = cells[0].text.strip()\n",
    "                    size = cells[1].text.strip()  # \"File size\" â†’ stored as \"Size\"\n",
    "\n",
    "                    # Infer file type from filename (second-to-last extension)\n",
    "                    parts = file_name.split(\".\")\n",
    "                    file_type = parts[1] if len(parts) > 1 else \"unknown\"\n",
    "\n",
    "                    # Skip \"(all files)\" entry\n",
    "                    if file_name.lower() == \"(all files)\":\n",
    "                        continue\n",
    "\n",
    "                    row_dict = data.copy()\n",
    "                    row_dict.update({\n",
    "                        \"Supplementary file\": file_name,\n",
    "                        \"Size\": size,  # unified name\n",
    "                        \"File type/resource\": file_type\n",
    "                    })\n",
    "                    supp_data.append(row_dict)\n",
    "        finally:\n",
    "            driver.quit()\n",
    "\n",
    "        if not supp_data:\n",
    "            supp_data.append(data)\n",
    "\n",
    "    # -------------------------\n",
    "    # Case 2: Default parsing (original code)\n",
    "    # -------------------------\n",
    "    else:\n",
    "        tables = soup.find_all('table')\n",
    "        supp_table = None\n",
    "        for table in tables[::-1]:\n",
    "            header_row = table.find('tr')\n",
    "            if not header_row:\n",
    "                continue\n",
    "            headers = [cell.get_text(strip=True) for cell in header_row.find_all(['td', 'th'])]\n",
    "            if (\n",
    "                \"Supplementary file\" in headers\n",
    "                and \"Size\" in headers\n",
    "                and \"File type/resource\" in headers\n",
    "            ):\n",
    "                supp_table = table\n",
    "                break\n",
    "\n",
    "        if supp_table:\n",
    "            rows = supp_table.find_all('tr')[1:]  # skip header\n",
    "            for row in rows:\n",
    "                cells = row.find_all('td')\n",
    "                if len(cells) >= 4:\n",
    "                    file_name = cells[0].get_text(strip=True)\n",
    "                    size = cells[1].get_text(strip=True)\n",
    "                    file_type = cells[3].get_text(strip=True)\n",
    "                    row_dict = data.copy()\n",
    "                    row_dict.update({\n",
    "                        \"Supplementary file\": file_name,\n",
    "                        \"Size\": size,\n",
    "                        \"File type/resource\": file_type\n",
    "                    })\n",
    "                    supp_data.append(row_dict)\n",
    "        else:\n",
    "            # If no supplementary table, at least record metadata once\n",
    "            supp_data.append(data)\n",
    "\n",
    "    return supp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set output dir\n",
    "dir_base = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working already"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting GSEs from manual query on GEO DataSets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          GSE    Cluster\n",
      "0    GSE40407   Cluster1\n",
      "1    GSE48568   Cluster2\n",
      "2    GSE59620   Cluster3\n",
      "3    GSE94758   Cluster4\n",
      "4   GSE112996   Cluster5\n",
      "..        ...        ...\n",
      "75  GSE285327  Cluster65\n",
      "76  GSE285328  Cluster65\n",
      "77  GSE285332  Cluster65\n",
      "78  GSE285341  Cluster65\n",
      "79  GSE291687  Cluster66\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "gds_file_path = os.path.join(dir_base, \"gds_result.txt\")\n",
    "proximity_window = 10  # Define how close the GSE numeric IDs should be to belong in the same group\n",
    "\n",
    "# Step 1: Read the file content\n",
    "with open(gds_file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Step 2: Extract all GSE accession IDs\n",
    "gse_ids = gse_ids = re.findall(r'GSE(\\d+)\\b', text)  # Just numeric parts as strings\n",
    "gse_ids = sorted(set(gse_ids), key=int)  # Sort numerically and unique\n",
    "\n",
    "# Step 3: Cluster GSEs by numeric proximity\n",
    "clusters = []\n",
    "cluster_index = 0\n",
    "current_cluster = []\n",
    "prev_num = None\n",
    "\n",
    "for gse_num_str in gse_ids:\n",
    "    gse_num = int(gse_num_str)\n",
    "    if prev_num is None:\n",
    "        # start first cluster\n",
    "        current_cluster = [gse_num]\n",
    "        cluster_index = 1\n",
    "    else:\n",
    "        # check if current gse_num is \"close\" to prev_num to be in the same cluster\n",
    "        if gse_num - prev_num <= proximity_window:\n",
    "            current_cluster.append(gse_num)\n",
    "        else:\n",
    "            # finalize current cluster, start new\n",
    "            clusters.append((cluster_index, current_cluster))\n",
    "            cluster_index += 1\n",
    "            current_cluster = [gse_num]\n",
    "    prev_num = gse_num\n",
    "\n",
    "# Add last cluster if not empty\n",
    "if current_cluster:\n",
    "    clusters.append((cluster_index, current_cluster))\n",
    "\n",
    "# Step 4: Create a mapping from GSE number to cluster index\n",
    "gse_to_cluster = {}\n",
    "for cluster_id, gse_list in clusters:\n",
    "    for val in gse_list:\n",
    "        gse_to_cluster[val] = cluster_id\n",
    "\n",
    "# Step 5: Build DataFrame with columns 'GSE' and 'Cluster'\n",
    "data = []\n",
    "for gse_num_str in gse_ids:\n",
    "    gse_num = int(gse_num_str)\n",
    "    cluster_id = gse_to_cluster.get(gse_num, None)\n",
    "    gse_code = f\"GSE{gse_num_str}\"\n",
    "    data.append({\"GSE\": gse_code, \"Cluster\": f\"Cluster{cluster_id}\"})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.drop_duplicates(subset=['GSE']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Optional: save to CSV\n",
    "df.to_csv(dir_base + \"/gds_processed.csv\", index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scraping each GSE into a dataframe output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing GSE40407 ...\n",
      "Processing GSE48568 ...\n",
      "Processing GSE59620 ...\n",
      "Processing GSE94758 ...\n",
      "Processing GSE112996 ...\n",
      "Processing GSE114989 ...\n",
      "Processing GSE122688 ...\n",
      "Processing GSE122689 ...\n",
      "Processing GSE146161 ...\n",
      "Processing GSE147196 ...\n",
      "Processing GSE147580 ...\n",
      "Processing GSE147665 ...\n",
      "Processing GSE155722 ...\n",
      "Processing GSE155723 ...\n",
      "Processing GSE155724 ...\n",
      "Processing GSE156231 ...\n",
      "Processing GSE156232 ...\n",
      "Processing GSE157711 ...\n",
      "Processing GSE158803 ...\n",
      "Processing GSE160711 ...\n",
      "Processing GSE162798 ...\n",
      "Processing GSE168233 ...\n",
      "Processing GSE172416 ...\n",
      "Processing GSE174743 ...\n",
      "Processing GSE174749 ...\n",
      "Processing GSE189925 ...\n",
      "Processing GSE193460 ...\n",
      "Processing GSE200563 ...\n",
      "Processing GSE200916 ...\n",
      "Processing GSE207592 ...\n",
      "Processing GSE215858 ...\n",
      "Processing GSE216055 ...\n",
      "Processing GSE216069 ...\n",
      "Processing GSE218989 ...\n",
      "Processing GSE221322 ...\n",
      "Processing GSE221733 ...\n",
      "Processing GSE222859 ...\n",
      "Processing GSE222901 ...\n",
      "Processing GSE223501 ...\n",
      "Processing GSE227560 ...\n",
      "Processing GSE228355 ...\n",
      "Processing GSE229353 ...\n",
      "Processing GSE235675 ...\n",
      "Processing GSE237782 ...\n",
      "Processing GSE237849 ...\n",
      "Processing GSE242951 ...\n",
      "Processing GSE244117 ...\n",
      "Processing GSE244123 ...\n",
      "Processing GSE245467 ...\n",
      "Processing GSE249568 ...\n",
      "Processing GSE250509 ...\n",
      "Processing GSE252703 ...\n",
      "Processing GSE259387 ...\n",
      "Processing GSE260598 ...\n",
      "Processing GSE260599 ...\n",
      "Processing GSE261345 ...\n",
      "Processing GSE261348 ...\n",
      "Processing GSE261799 ...\n",
      "Processing GSE263386 ...\n",
      "Processing GSE265899 ...\n",
      "Processing GSE268004 ...\n",
      "Processing GSE268048 ...\n",
      "Processing GSE268049 ...\n",
      "Processing GSE268426 ...\n",
      "Processing GSE268478 ...\n",
      "Processing GSE268525 ...\n",
      "Processing GSE269026 ...\n",
      "Processing GSE270231 ...\n",
      "Processing GSE271689 ...\n",
      "Processing GSE272466 ...\n",
      "Processing GSE272467 ...\n",
      "Processing GSE272469 ...\n",
      "Processing GSE283462 ...\n",
      "Processing GSE283829 ...\n",
      "Processing GSE285298 ...\n",
      "Processing GSE285327 ...\n",
      "Processing GSE285328 ...\n",
      "Processing GSE285332 ...\n",
      "Processing GSE285341 ...\n",
      "Processing GSE291687 ...\n",
      "                                                  Title  \\\n",
      "0     Characterizing the molecular spatial and tempo...   \n",
      "1     Characterizing the molecular spatial and tempo...   \n",
      "2     Characterizing the molecular spatial and tempo...   \n",
      "3     Characterizing the molecular spatial and tempo...   \n",
      "4     Characterizing the molecular spatial and tempo...   \n",
      "...                                                 ...   \n",
      "3504  KRAS G12C inhibition combined with CD47 and im...   \n",
      "3505  KRAS G12C inhibition combined with CD47 and im...   \n",
      "3506  KRAS G12C inhibition combined with CD47 and im...   \n",
      "3507  KRAS G12C inhibition combined with CD47 and im...   \n",
      "3508  KRAS G12C inhibition combined with CD47 and im...   \n",
      "\n",
      "                                                Summary  \\\n",
      "0     Gene expression alterations in response to cig...   \n",
      "1     Gene expression alterations in response to cig...   \n",
      "2     Gene expression alterations in response to cig...   \n",
      "3     Gene expression alterations in response to cig...   \n",
      "4     Gene expression alterations in response to cig...   \n",
      "...                                                 ...   \n",
      "3504  Although KRAS G12C inhibitors have altered the...   \n",
      "3505  Although KRAS G12C inhibitors have altered the...   \n",
      "3506  Although KRAS G12C inhibitors have altered the...   \n",
      "3507  Although KRAS G12C inhibitors have altered the...   \n",
      "3508  Although KRAS G12C inhibitors have altered the...   \n",
      "\n",
      "                                         Overall design   Contact name  \\\n",
      "0     Bronchial brushings and biopsies were obtained...   Humam Kadara   \n",
      "1     Bronchial brushings and biopsies were obtained...   Humam Kadara   \n",
      "2     Bronchial brushings and biopsies were obtained...   Humam Kadara   \n",
      "3     Bronchial brushings and biopsies were obtained...   Humam Kadara   \n",
      "4     Bronchial brushings and biopsies were obtained...   Humam Kadara   \n",
      "...                                                 ...            ...   \n",
      "3504  LLC Nras KO syngeneic lung tumors were treated...  Hiromichi Ebi   \n",
      "3505  LLC Nras KO syngeneic lung tumors were treated...  Hiromichi Ebi   \n",
      "3506  LLC Nras KO syngeneic lung tumors were treated...  Hiromichi Ebi   \n",
      "3507  LLC Nras KO syngeneic lung tumors were treated...  Hiromichi Ebi   \n",
      "3508  LLC Nras KO syngeneic lung tumors were treated...  Hiromichi Ebi   \n",
      "\n",
      "                                  Organization name     City State/province  \\\n",
      "0     University of Texas MD Anderson Cancer Center  Houston             TX   \n",
      "1     University of Texas MD Anderson Cancer Center  Houston             TX   \n",
      "2     University of Texas MD Anderson Cancer Center  Houston             TX   \n",
      "3     University of Texas MD Anderson Cancer Center  Houston             TX   \n",
      "4     University of Texas MD Anderson Cancer Center  Houston             TX   \n",
      "...                                             ...      ...            ...   \n",
      "3504         Aichi Cancer Center Research Institute   Nagoya          Aichi   \n",
      "3505         Aichi Cancer Center Research Institute   Nagoya          Aichi   \n",
      "3506         Aichi Cancer Center Research Institute   Nagoya          Aichi   \n",
      "3507         Aichi Cancer Center Research Institute   Nagoya          Aichi   \n",
      "3508         Aichi Cancer Center Research Institute   Nagoya          Aichi   \n",
      "\n",
      "     Country Platforms  Samples     Series SuperSeries  \\\n",
      "0        USA   GPL6244      391   GSE40407    GSE40407   \n",
      "1        USA   GPL6244      391   GSE40407    GSE40407   \n",
      "2        USA   GPL6244      391   GSE40407    GSE40407   \n",
      "3        USA   GPL6244      391   GSE40407    GSE40407   \n",
      "4        USA   GPL6244      391   GSE40407    GSE40407   \n",
      "...      ...       ...      ...        ...         ...   \n",
      "3504   Japan  GPL34290        2  GSE291687   GSE291687   \n",
      "3505   Japan  GPL34290        2  GSE291687   GSE291687   \n",
      "3506   Japan  GPL34290        2  GSE291687   GSE291687   \n",
      "3507   Japan  GPL34290        2  GSE291687   GSE291687   \n",
      "3508   Japan  GPL34290        2  GSE291687   GSE291687   \n",
      "\n",
      "                                  Supplementary file      Size  \\\n",
      "0                     GSM992943_1188_VANG_001.CEL.gz    4.3 Mb   \n",
      "1                     GSM992944_1188_VANG_002.CEL.gz    4.3 Mb   \n",
      "2                     GSM992945_1188_VANG_003.CEL.gz    4.2 Mb   \n",
      "3                     GSM992946_1188_VANG_004.CEL.gz    4.0 Mb   \n",
      "4                     GSM992947_1188_VANG_005.CEL.gz    4.0 Mb   \n",
      "...                                              ...       ...   \n",
      "3504  GSM8840045_SL-D1-filtered_feature_bc_matrix.h5   87.3 Mb   \n",
      "3505      GSM8840045_SL-D1-scalefactors_json.json.gz     233 b   \n",
      "3506      GSM8840045_SL-D1-tissue_hires_image.png.gz   42.4 Mb   \n",
      "3507     GSM8840045_SL-D1-tissue_lowres_image.png.gz  354.9 Kb   \n",
      "3508        GSM8840045_SL-D1-tissue_positions.csv.gz   16.2 Mb   \n",
      "\n",
      "     File type/resource         E-mail(s) Phone  \\\n",
      "0                   CEL               NaN   NaN   \n",
      "1                   CEL               NaN   NaN   \n",
      "2                   CEL               NaN   NaN   \n",
      "3                   CEL               NaN   NaN   \n",
      "4                   CEL               NaN   NaN   \n",
      "...                 ...               ...   ...   \n",
      "3504                 h5  hebi@aichi-cc.jp   NaN   \n",
      "3505               json  hebi@aichi-cc.jp   NaN   \n",
      "3506                png  hebi@aichi-cc.jp   NaN   \n",
      "3507                png  hebi@aichi-cc.jp   NaN   \n",
      "3508                csv  hebi@aichi-cc.jp   NaN   \n",
      "\n",
      "                              Department  Lab  \n",
      "0                                    NaN  NaN  \n",
      "1                                    NaN  NaN  \n",
      "2                                    NaN  NaN  \n",
      "3                                    NaN  NaN  \n",
      "4                                    NaN  NaN  \n",
      "...                                  ...  ...  \n",
      "3504  Division of Molecular Therapeutics  NaN  \n",
      "3505  Division of Molecular Therapeutics  NaN  \n",
      "3506  Division of Molecular Therapeutics  NaN  \n",
      "3507  Division of Molecular Therapeutics  NaN  \n",
      "3508  Division of Molecular Therapeutics  NaN  \n",
      "\n",
      "[3509 rows x 19 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of GSE IDs to process\n",
    "gse_list = df['GSE']  # replace with your GSEs\n",
    "\n",
    "all_data = []\n",
    "for gse in gse_list:\n",
    "    print(f\"Processing {gse} ...\")\n",
    "    all_data.extend(process_gse(gse))\n",
    "\n",
    "df_combined = pd.DataFrame(all_data)\n",
    "\n",
    "# Save all results to CSV\n",
    "os.makedirs(dir_base, exist_ok=True)\n",
    "combined_path = os.path.join(dir_base, \"geo_webscrap.csv\")\n",
    "df_combined.to_csv(combined_path, index=False)\n",
    "\n",
    "print(df_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KIDS2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
